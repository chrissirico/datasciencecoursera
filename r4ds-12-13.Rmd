---
title: "Ch 12-13 r4ds hw"
author: "Chris Sirico"
date: "10/6/2017"
output: html_document
---
# R4DS Ch. 12 - 13 Exercises 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(nycflights13)
library(maps)
library(Lahman)
library(nasaweather)
library(babynames)
```

## 12.2.1

1.  **Using prose, describe how the variables and observations are organised in
    each of the sample tables.**
    
`table1` Layed out with variables in columns and observations by country in rows.

`table2` This table conflates values of numbers of cases and total population in the same column (`count`) and stores variable data (`cases`/`population`) in the `type` column.
    
`table3` This table combines the variables of cases and population in the right column, `rate`.
    
`table4a / table4b` These tables don't have a column for the variables `cases` and `population`, but rather split them between tables, which makes it harder to calculate rate. 
    
1.  **Compute the `rate` for `table2`, and `table4a` + `table4b`. 
    You will need to perform four operations:**

    1.  Extract the number of TB cases per country per year.
    1.  Extract the matching population per country per year.
    1.  Divide cases by population, and multiply by 10000.
    1.  Store back in the appropriate place.
    
```{r}
#recreate table2
table2 <- tibble(
  country = c("Afghanistan","Afghanistan","Afghanistan","Afghanistan","Brazil","Brazil","Brazil","Brazil","China","China","China","China"),
  year = parse_integer(c(1999,1999,2000,2000,1999,1999,2000,2000,1999,1999,2000,2000)),
  type = c("cases","population","cases","population","cases","population","cases","population","cases","population","cases","population"),
  count = parse_integer(c(745,19987071,2666,20595360,37737,172006362,80488,174504898,212258,1272915272,213766,1280428583)))

#Extract to vectors
country_v <- filter(table2, type == "cases")[["country"]]
year_v <- filter(table2, type == "cases")[["year"]]
count_v <- filter(table2, type == "cases")[["count"]]
pop_v <- filter(table2, type == "population")[["count"]]

# Reconstitute, divide & multiply into tibble
tb2rate <- tibble(country = country_v,
       year = year_v,
       cases = count_v,
       population = pop_v,
       rate = count_v / pop_v * 10000 
)
tb2rate %>% print

#recreate table4a
table4a <- tibble(
  country = c("Afghanistan","Brazil","China"),
  "1999" = parse_integer(c(745,37737,212258)),
  "2000" = parse_integer(c(2666,80488,213766)))

#recreate table4b
table4b <- tibble(
  country = c("Afghanistan","Brazil","China"),
  "1999" = parse_integer(c(19987071,172006362,1272915272)),
  "2000" = parse_integer(c(20595360,174504898,1280428583)))

countries <- table4a[["country"]]
cases <- c(table4a[["1999"]],table4a[["2000"]])
populations <- c(table4b[["1999"]],table4b[["2000"]])

# hacky way to get three of each year in ascending order into a vector
years <- tibble( year =
  c(
    ((select(table4a, -country) %>% colnames())),
    ((select(table4a, -country) %>% colnames())),
    ((select(table4a, -country) %>% colnames()))
   )
  ) %>%
  arrange(year)
years <- years[[1]]

# years <- select(table4a, -country) %>% colnames()

new_df <- tibble(
  country = c(countries,countries),
  year = years,
  case_num = cases,
  population = populations,
  rate = case_num / population * 10000
)
(new_df)
```
 
    **Which representation is easiest to work with? Which is hardest? Why?**
    
    `table1` would've been the easiest because it's tidy! `table2` was easier than tables `4a` and `4b` because all the data was in the same place.

**1.  Recreate the plot showing change in cases over time using `table2` instead of `table1`. What do you need to do first?**

  We need to filter out "population" rows from column `type` so we're left with only count.

```{r echo=FALSE, out.width = "50%"}
#build table2 
table2 <- tibble(
  country = c("Afghanistan","Afghanistan","Afghanistan","Afghanistan","Brazil","Brazil","Brazil","Brazil","China","China","China","China"),
  year = parse_integer(c(1999,1999,2000,2000,1999,1999,2000,2000,1999,1999,2000,2000)),
  type = c("cases","population","cases","population","cases","population","cases","population","cases","population","cases","population"),
  count = parse_integer(c(745,19987071,2666,20595360,37737,172006362,80488,174504898,212258,1272915272,213766,1280428583)))

filter(table2, type == "cases") %>%

# Visualise changes over time
ggplot(aes(year, count)) + 
  geom_line(aes(group = country), colour = "grey50") + 
  geom_point(aes(colour = country))
```

## 12.3.3 Exercises
<!--
```{r}
#recreate table2
table2 <- tibble(
  country = c("Afghanistan","Afghanistan","Afghanistan","Afghanistan","Brazil","Brazil","Brazil","Brazil","China","China","China","China"),
  year = parse_integer(c(1999,1999,2000,2000,1999,1999,2000,2000,1999,1999,2000,2000)),
  type = c("cases","population","cases","population","cases","population","cases","population","cases","population","cases","population"),
  count = parse_integer(c(745,19987071,2666,20595360,37737,172006362,80488,174504898,212258,1272915272,213766,1280428583)))

#columns to gather, key (what to call those vars), value (column name for the stuff in the cells to put in a column next to the key column)

# EXAMPLE STUFF
tidy4a <- table4a %>% 
  gather(`1999`, `2000`, key = "year", value = "cases")
tidy4b <- table4b %>% 
  gather(`1999`, `2000`, key = "year", value = "population")
left_join(tidy4a, tidy4b)

# figure out spread
table2 <- table2 %>% spread(type, count)

library(dplyr)
stocks <- data.frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
)
stocksm <- stocks %>% gather(stock, price, -time)
stocksm %>% spread(stock, price)
stocksm %>% spread(time, price)

# Spread and gather are complements
df <- data.frame(x = c("a", "b"), y = c(3, 4), z = c(5, 6))
df %>% spread(x, y) %>% gather(x, y, a:b, na.rm = TRUE)
#REAL START OF BELOW 
``` 
-->

1.  **Why are `gather()` and `spread()` not perfectly symmetrical?
    Carefully consider the following example:**
    
```{r, eval = FALSE}
    stocks <- tibble(
      year   = c(2015, 2015, 2016, 2016),
      half  = c(   1,    2,     1,    2),
      return = c(1.88, 0.59, 0.92, 0.17)
    )
    
    stocks %>% print
    
    stocks %>% 
      spread(year, return) %>% print
    
    stocks %>% 
      spread(year, return) %>% # print
      gather("year", "return", `2015`:`2016`) %>% print
    
    stocks %>% 
      spread(year, return) %>% # print
      gather("year", "return", `2015`:`2016`) %>% print
```
    
(Hint: look at the variable types and think about column _names_.)
    
Spread deletes year, thus erasing its position in the column order. Gather reintroduces year and return, but it does so at the right edge of our dataframe. It also creates the new variable as type character instead of integer.
    
**Both `spread()` and `gather()` have a `convert` argument. What does it 
    do?**
    
`convert = TRUE` allows `spread` to automatically create variables of a type appropriate to the contents.


1.  **Why does this code fail?**

```{r, error = TRUE}
    table4a %>% 
      gather(1999, 2000, key = "year", value = "cases")
```

  Years are non-syntactic and must be escaped with backticks.

1.  **Why does spreading this tibble fail? How could you add a new column to fix
    the problem?**

```{r}
    people <- tribble(
      ~name,             ~key,    ~value,
      #-----------------|--------|------
      "Phillip Woods",   "age",       45,
      "Phillip Woods",   "height",   186,
      "Phillip Woods",   "age",       50,
      "Jessica Cordero", "age",       37,
      "Jessica Cordero", "height",   156
    )
   
   spread(people, key, value)
```

There is no differentiating variable for Phillip Woods' two age observations. We could add a column with the year, an ID or something similar.

1.  **Tidy the simple tibble below. Do you need to spread or gather it?
    What are the variables?**

```{r}
    preg <- tribble(
      ~pregnant, ~male, ~female,
      "yes",     NA,    10,
      "no",      20,    12
    )
    
    # Vars are sex, pregnant and count. Needs to be gathered.
    
    gather(preg, male, female, key = "sex", value = "count")
```

## 12.4.3 Exercises

1.  **What do the `extra` and `fill` arguments do in `separate()`? 
    Experiment with the various options for the following two toy datasets.**
    
    `fill` tells R on which edge of the table to put missing values.
    `extra` specifies whether extra values are merged into the last cell or dropped.
    
    ```{r}
    tibble(x = c("a,b,c", "d,e,f,g,h", "h,i,j")) %>% 
      separate(x, c("one", "two", "three"), extra = "merge")
    
    tibble(x = c("a,b,c", "d,e", "f,g,i")) %>% 
      separate(x, c("one", "two", "three"), fill = "left", remove = F)
    ```

1.  **Both `unite()` and `separate()` have a `remove` argument. What does it
    do? Why would you set it to `FALSE`?**
    
    You can preserve the orginal column and split the output to additional columns if you want to munge non-destructively.

1.  **Compare and contrast `separate()` and `extract()`.  Why are there
    three variations of separation (by position, by separator, and with
    groups), but only one unite?**
    
    Okay, so. Extract grabs just the parts you want, while separate grabs everything except separator characters. It's necessary to have several ways to split values because there are many ways data can be combined in a column. You only need one function for combining multiple columns, because that separation is explicit in the structure of the data.
``` {r}   
library(dplyr)
df <- data.frame(x = c("aoueao-oeu", "a-b", "a-d", "b-c", "d-e"))
df %>% extract(x, "A")
# ([[:alnum:]]+) seems to be telling the function to look for an alphanumeric character. Seems like it returns NA if it fails to find something that matches exclusively.
df %>% extract(x, c("A", "B"), "([[:alnum:]]+)-([[:alnum:]]+)")

# If no match, NA:
df %>% extract(x, c("A", "B"), "([a-d]+)-([a-d]+)")
```

## 12.5.1 Exercises

1.  **Compare and contrast the `fill` arguments to `spread()` and `complete()`.** 

`fill` takes the dataset and a column and does the rest to get rid of missing values.
`complete` takes similar arguments, but makes all missing value combinations explicit.
`spread` takes the dataset, a column whose values should become column names, and the column whose values should be spread below the new columns.

1.  **What does the direction argument to `fill()` do?**
It tells the function whether to pull values `down` or `up` into NA cells. Default is `down`.

## 12.6.1 Exercises
```{r}
who %>%
  gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1)
```

1.  **In this case study I set `na.rm = TRUE` just to make it easier to check that we had the correct values. Is this reasonable? Think about how missing values are represented in this dataset. Are there implicit missing values? What's the difference between an `NA` and zero?**

Leaving the missing values in gives a clearer picture of what is and is not present. NA shows that the measurements weren't taken. Zero would imply that the statistic was measured and there were no cases. It doesn't look like there are any implicit missing values until we gather with na.rm = TRUE.

1.  **What happens if you neglect the `mutate()` step?
    (`mutate(key = stringr::str_replace(key, "newrel", "new_rel"))`)**
    newrel gets separated into the `new` column and then omitted from the data with the select function.

1.  **I claimed that `iso2` and `iso3` were redundant with `country`. 
    Confirm this claim.**
    Counting the number of occurences of each name yields the same results:
``` {r}
    count(who, iso3)
    count(who, iso2)
    count(who, country)
```
1.  For each country, year, and sex compute the total number of cases of TB. Make an informative visualisation of the data.
```{r}
who %>%
  gather(code, value, new_sp_m014:newrel_f65, na.rm = TRUE) %>% 
  mutate(code = stringr::str_replace(code, "newrel", "new_rel")) %>%
  separate(code, c("new", "var", "sexage")) %>% 
  select(-new, -iso2, -iso3) %>% 
  separate(sexage, c("sex", "age"), sep = 1) %>%
  group_by(country, sex, year) %>%
  summarize(totals = sum(value)) %>%
  arrange(desc(totals)) %>%
  filter(totals >= 100000) %>%
  
  ggplot(aes(country,year)) +
  geom_point(aes(color=sex, size=totals)) +
  coord_flip()

```
    
    
    ## CHAPTER 13
    
    ## 13.2.1 Exercises
    
1.  **Imagine you wanted to draw (approximately) the route each plane flies from
    its origin to its destination. What variables would you need? What tables
    would you need to combine?**
    One would need all combinations of origin and destination as well as the lat/longs of those airports. You'd have to join airports and flights.

1.  **I forgot to draw the relationship between `weather` and `airports`.
    What is the relationship and how should it appear in the diagram?**
    
    Weather origin would connect to airports `faa`.

1.  **`weather` only contains information for the origin (NYC) airports. If
    it contained weather records for all airports in the USA, what additional
    relation would it define with `flights`?**
    
    Destination

1.  **We know that some days of the year are "special", and fewer people than
    usual fly on them. How might you represent that data as a data frame?
    What would be the primary keys of that table? How would it connect to the
    existing tables?**
    
    I'd create a datatable called holidays and relate it to flights by the date columns.

## 13.3.1 Exercises
  
1.  **Add a surrogate key to `flights`.**

```{r eval=FALSE}
mutate(flights,
       id = row_number()) %>%
  select(id, everything())
```
2.  **Identify the keys in the following datasets
    (You might need to install some packages and read some documentation.)**

    1.  `Lahman::Batting` -- playerID, yearID, stint
    1.  `babynames::babynames` -- name, sex, year
    1.  `nasaweather::atmos` -- lat, long, year, month
    1.  `fueleconomy::vehicles` -- id (yay!)
    1.  `ggplot2::diamonds` -- HA HA! trick question. Some observations are exactly identical.
    
3.  **Draw a diagram illustrating the connections between the `Batting`,
    `Master`, and `Salaries` tables in the Lahman package. Draw another diagram
    that shows the relationship between `Master`, `Managers`, `AwardsManagers`.**
    
     Master keys to Batting and Salaries on playerID. Salaries could key to Batting on playerID, year and team.
     
     Master keys to Managers on playerID, year and team. AwardsManagers keys to Managers on year and playerID.
     

    **How would you characterise the relationship between the `Batting`,
    `Pitching`, and `Fielding` tables?**
    
    The primary keys are the same, but the individual metrics vary by table.
    
## 13.4.6 Exercises

1.  **Compute the average delay by destination, then join on the `airports`
    data frame so you can show the spatial distribution of delays. Here's an
    easy way to draw a map of the United States:**
```{r}
flights3 <- group_by(flights, dest) %>%
mutate(avg_delay = mean(arr_delay, na.rm = T))

flights3 %>%
      left_join(airports, c("dest" = "faa")) %>% 
      ggplot(aes(lon, lat)) +
        borders("state") +
        geom_point(aes(color = avg_delay), na.rm = T) +
        coord_quickmap()

```
**(Don't worry if you don't understand what `semi_join()` does --- you'll
    learn about it next.)

    You might want to use the `size` or `colour` of the points to display
    the average delay for each airport.**

2.  **Add the location of the origin _and_ destination (i.e. the `lat` and `lon`)
    to `flights`.**
    
```{r}
flights %>% 
left_join(airports, by = c("dest" = "faa"), suffix = c(".d",".o")) %>%
left_join(airports, by = c("origin" = "faa"), suffix = c(".d", ".o"))
```
3.  Is there a relationship between the age of a plane and its delays?
```{r}
flights %>% group_by(tailnum) %>%
  summarise(arr_delay = mean(arr_delay, na.rm=T)) %>% 
  left_join(planes, by = c("tailnum")) %>%
  mutate(age = 2013 - year) %>%
  ggplot(aes(age, arr_delay)) +
  geom_point(alpha=.2, na.rm = T) +
  geom_smooth()
```
Planes seem to have slightly more delays at their 10-year-old phase, although that may have to do with outliers clustering around the densest area of airplane age.

4.  What weather conditions make it more likely to see a delay?

```{r}
flights %>% group_by(origin, year, month, day, hour) %>%
  summarise(dep_delay = mean(dep_delay, na.rm=T)) %>% 
  left_join(weather, by = c("year", "month", "day", "hour", "origin")) %>% 
    ggplot(aes(x=dep_delay))+
  geom_point(aes(y=temp), color="black", alpha=.05) +
  geom_point(aes(y=dewp), color="yellow", alpha=.05) +
  geom_point(aes(y=humid), color="orange", alpha=.05) +
  geom_point(aes(y=wind_dir), color="purple", alpha=.05) +
  geom_point(aes(y=wind_speed), color="magenta", alpha=.05) +
  geom_point(aes(y=wind_gust), color="cyan", alpha=.05) +
  geom_point(aes(y=precip), color="green", alpha=.1) +
  geom_point(aes(y=pressure), color="blue", alpha=.1) +
  geom_point(aes(y=visib), color="red", alpha=.1)


```
Hours with lower visibilities seem to have a higher proportion of delays.

5.  **What happened on June 13 2013? Display the spatial pattern of delays,
    and then use Google to cross-reference with the weather.**
  
```{r}
flights3 <- group_by(flights, dest) %>%
filter(month == 6, day == 13) %>%
mutate(avg_delay = mean(arr_delay, na.rm = T))

flights3 %>%
      left_join(airports, c("dest" = "faa")) %>% 
      ggplot(aes(lon, lat)) +
        borders("state") +
        geom_point(aes(color = avg_delay), na.rm = T) +
        coord_quickmap()

```
    Pretty stout delays all over the eastern U.S. Google results talk about the derecho, a phenomenon that seems to cause thunderstorms.
    
## 13.5.1 Exercises    

1.  **What does it mean for a flight to have a missing `tailnum`? What do the tail numbers that don't have a matching record in `planes` have in common?
    (Hint: one variable explains ~90% of the problems.)**
```{r}
flights %>%
  anti_join(planes, by = "tailnum") %>%
  count(carrier, sort = TRUE)
```
AA and MQ seem to omit tail numbers.

1.  Filter flights to only show flights with planes that have flown at least 100
    flights.
``` {r}    
century <- flights %>%
  count(tailnum) %>% 
  filter(n >= 100)
century
```

1.  Combine `fueleconomy::vehicles` and `fueleconomy::common` to find only the
    records for the most common models.
```{r}
semi_join(vehicles, common)
```
1.  Find the 48 hours (over the course of the whole year) that have the worst
    delays. Cross-reference it with the `weather` data. Can you see any
    patterns?

```{r}
#find delayedest 48 hrs
flights4 <- group_by(flights, year, month, day, origin) %>%
  summarize(avg_delay = mean(arr_delay, na.rm=T)) %>%
  mutate(neigh_sum = mean(avg_delay + lag(avg_delay), na.rm=T)) %>% #I would weight this combination of day averages by number of flights if I was a good person.
  arrange(desc(neigh_sum))

flights4

#group this bad boy into 48 hr periods
weather4 <- group_by(weather, year, month, day, origin) %>%
  summarize(avg_precip = mean(precip, na.rm=T),
            avg_visib = mean(visib, na.rm=T),
            avg_wind_speed = mean(wind_speed, na.rm=T)) %>%
  mutate(precip48 = mean(avg_precip + lag(avg_precip), na.rm=T),
         visib48 = mean(avg_visib + lag(avg_visib), na.rm=T),
         wind_speed48 = mean(avg_wind_speed + lag(avg_wind_speed), na.rm=T)) %>%
  arrange(visib48, desc(wind_speed48), desc(precip48)) 

weather4
# join
flight_weather <- left_join(flights4, weather4, c("year", "month", "day", "origin")) 

# plot by precip
ggplot(flight_weather) +
  geom_point(aes(x=avg_delay, y=precip48), alpha=.1)

# plot by visib
ggplot(flight_weather) +
  geom_point(aes(x=avg_delay, y=visib48), alpha=.1)

# plot by wind_speed
ggplot(flight_weather) +
  geom_point(aes(x=avg_delay, y=wind_speed48), alpha=.1)

# All three of these variables seem to have some small correlation with delay times, especially visibility and wind speed. Further exploration could include looking at other weather measurements, especially barometric pressure. We could calculate the level correlation to better understand the strength of the connection.

```
Looking at most-delayed 48-hr periods and worst 48-hr periods for visibility, precipitation and windspeed, there's no immediately obvious pattern.

1.  What does `anti_join(flights, airports, by = c("dest" = "faa"))` tell you?

flights to airports not in the FAA list (foreign cities)

    What does `anti_join(airports, flights, by = c("faa" = "dest"))` tell you?

US airports that received flights from nyc in 2013

1.  You might expect that there's an implicit relationship between plane
    and airline, because each plane is flown by a single airline. Confirm
    or reject this hypothesis using the tools you've learned above.
    
    Planes seem to be shared by airlines rather often.
    
    ``` {r}
multi_owned <- flights %>%
  group_by(tailnum) %>%
  summarise(owners = n_distinct(carrier)) %>% 
  filter(owners >1)
    
filter(flights, tailnum %in% multi_owned[["tailnum"]]) %>%
  group_by(tailnum, carrier, dest, month) %>%
  summarize(n()) %>%
  left_join(airlines, by = "carrier", )

# ExpressJet apparently bought several planes from Endeavor air, which transferred ownership in March.
# Delta also got planes from AirTran in October.
# About 17 planes in this ecosystem seem to have changed hands in 2013.
  
    ```
